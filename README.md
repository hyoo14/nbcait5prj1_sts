# STS(Semantic Text Similarity, STS)

Semantic Text Similarity (STS) is a natural language processing task that quantifies how similar two sentences are in terms of meaning.

#BC 5th #NLP

Period| 2023.04.12 ~ 2023.04.20 19:00

[í•œê¸€ë¡œ ë³´ê¸°](https://github.com/bootcamphyunwoo/naver_bcait5_lv1_prj1_nlp_sts)

## Introduction

When writing for information transfer purposes, such as in reports or papers, we often find ourselves repeating the same phrases or sentences. Redundant sentences can be one of the factors that decrease readability, thereby reducing the overall quality of the text. In such cases, humans undergo a correction process, recognizing and revising semantically redundant sentences. But how can a machine distinguish between sentences that are structurally different but semantically similar?

**![](https://lh5.googleusercontent.com/veZu5SdKvujQWfYi1_HgnA8J4IARC_51yWIQbZSpfmLhQEuFhBUk4jAmktg-8z1kWKgB62tOot8px6RfJR1BL81RNvhdpirrrXQDFr-cKhg4mroMu2_NNRGwnJAlMyxPQMzA1xTqLn9103KVVuud6-M)**

What is contextual similarity measurement?

A task that can be used in such cases is Semantic Text Similarity (STS). STS is an NLP task that determines how similar two texts are. Typically, it takes two sentences as input and assesses how semantically similar the pair of sentences is.

**![](https://lh5.googleusercontent.com/lMF4vMp9MkHjhw1utnPLTgpGA6fH7NrsU5h9gVMu7BssGfEGDeec0LQU0opahJXCQVz9oArM55SM1o-npfAv96x2q2Y6OzGM9Ph-9D5IZylsbomevV5IGFvY9eawaRfv1gx6lKOXRz8igiTWVOfbI2s)**

Differences between Textual Entailment and Semantic Text Similarity

It can be confusing to distinguish Textual Entailment (TE) from Semantic Text Similarity (STS) since both predict relationships. The most significant difference between the two problems is their 'directionality'. While STS operates under the assumption of bidirectional equivalence between two sentences, TE inherently has directionality. For instance, while a car is a mode of transportation, the set of modes of transportation doesn't exclusively contain cars. Additionally, there is a difference in their output forms. Both TE and STS can judge relational similarity as true/false, but STS can also produce a quantified score.

Such bidirectionality and the ability to quantify in STS have been widely utilized in NLP tasks like information extraction, question-answering, and summarization. In practical applications, it's employed for data augmentation, suggesting questions for chatbots, or detecting duplicate sentences.

We will construct an AI model that measures the similarity between two sentences using the STS dataset. While we provide reference information judging the similarity of two sentences as true or false along with a similarity score, our primary objective is to predict a similarity score between 0 and 5!

The training dataset consists of 9,324 items, the validation dataset has 550, and there are 1,100 items in the evaluation dataset. 50% of the evaluation data will be used for public score calculations and will be displayed on the real-time leaderboard, while the remaining 50% will be used for private results and evaluated after the competition ends.

The final submission for this competition will be in the form of a CSV extension file.

- Input: A CSV file containing two sentences, ID, and similarity information.

- Output: A CSV file containing the ID and similarity score for each pair of sentences in the evaluation data.

### Evaluation Metrics

The Pearson Correlation Coefficient (PCC) is a measure quantifying the linear correlation between two variables, X and Y. Typically, when referring to correlation, it denotes the Pearson correlation.

According to the Cauchy-Schwarz inequality, its value ranges between -1 and 1. A value of +1 indicates a perfect positive linear correlation, 0 indicates no linear correlation, and -1 indicates a perfect negative linear correlation.

![](https://lh5.googleusercontent.com/xONAwpoq9MXiZKe-09QUGU8so9pRhMboPTxOEG_Q2Z4QorEgtJamBFcOz6zjqt4IdCXw0z1NN3mCHIN805uWPUSTtVvKDyutCpB1AekQi2iBFaJou5DlFgwvidIR5Fcu75TydYmURYY90VXwdBbVX5I)

The Pearson Correlation Coefficient shows a value close to 1 even if the actual and predicted values don't match, as long as their rates of increase or decrease are consistent.

Conversely, even if the actual and predicted values are close, if their rates of increase or decrease differ, it can show a value closer to -1.

This indicates that rather than precisely predicting the correct values, it's more important to accurately predict the overall trend, ensuring higher values are indeed higher and lower values are decidedly lower.

## Team Approach

### PLM trials

We have tried BERT, RoBERTa, ELECTRA PLMs with base and large version as a plug-and-play way. In this project, ELECTRA PLM shows the best performance among other PLMs.

### Data Augmentations

For improving performance, we have tested various data augmentation methods such as swaping sentences, copying sentences.

### Fine-Tuning Methods

We have chose multitask learning method which used both binary similarity score and non-binary similarity score.

### Loss functions

There are many loss functions that we can use. For instance there are SMARTLoss, L1Loss, L2loss, MAE, MSE functions. SMARTLoss is operating with regarding the number of embeddings and we thought this loss function would be good for accomplishing good score. However, we have failed to apply this function because of short of time. We regreted that we didn't spend our time more to apply this.

### Hyperparameter Tuning

We did diverse tunings including learning rate(from 0.01 to 0.03), batch size and so on.

### Detailed Timeline

* Entire project duration (2 weeks): April 10th (Monday) 10:00 ~ April 20th (Thursday) 19:00
- Team merging period: Until April 11th (Tuesday) 16:00

- Team name convention: DomainTeamNumber(2 digits)_Group / ex) CV_03 Group, NLP_02 Group, RecSys_08 Group

- Leaderboard submission opens: April 12th (Wednesday) 10:00

- Leaderboard submission deadline: April 20th (Thursday) 19:00

- Final leaderboard (Private) release: April 20th (Thursday) 20:00

- GPU server allocation: April 10th (Monday) 10:00

- GPU server retrieval: April 28th (Friday) 16:00

### Competition Rules

- [ëŒ€íšŒ ì°¸ì—¬ ì œí•œ] NLP ë„ë©”ì¸ì„ ìˆ˜ê°•í•˜ê³  ìˆëŠ” ìº í¼ì— í•œí•˜ì—¬ ë¦¬ë”ë³´ë“œ ì œì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

- [íŒ€ ê²°ì„± ê¸°ê°„] íŒ€ ê²°ì„±ì€ ëŒ€íšŒ í˜ì´ì§€ ê³µê°œ í›„ 2ì¼ì°¨ ì˜¤í›„ 4ì‹œê¹Œì§€ í•„ìˆ˜ë¡œ ì§„í–‰í•´ ì£¼ì„¸ìš”. íŒ€ì´ ì™„ì „íˆ ê²°ì„±ë˜ê¸° ì „ê¹Œì§€ëŠ” ë¦¬ë”ë³´ë“œ ì œì¶œì´ ë¶ˆê°€í•©ë‹ˆë‹¤.

- [ì¼ì¼ ì œì¶œíšŸìˆ˜] ì¼ì¼ ì œì¶œíšŸìˆ˜ëŠ” 'íŒ€ ë‹¨ìœ„ 10íšŒ'ë¡œ ì œí•œí•©ë‹ˆë‹¤. (ì¼ì¼íšŸìˆ˜ ì´ˆê¸°í™” ìì • ì§„í–‰)

- [ì™¸ë¶€ ë°ì´í„°ì…‹ ê·œì •] ë³¸ ëŒ€íšŒì—ì„œëŠ” ì™¸ë¶€ ë°ì´í„°ì…‹ ì‚¬ìš©ì„ ê¸ˆì§€í•©ë‹ˆë‹¤. (ì™¸ë¶€ ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ë§ ì„±ëŠ¥ ê°œì„ ì— ì§‘ì¤‘í•´ ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤)

- [ê¸°í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš©] ì €ì‘ê¶Œìƒ ì‚¬ìš©ì´ ë¶ˆê°€í•œ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ ëŠ” ëª¨ë“  ê¸°í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš©ì€ í—ˆìš©ë©ë‹ˆë‹¤.

- [í…ŒìŠ¤íŠ¸ì…‹ í™œìš© ê°€ëŠ¥ ì—¬ë¶€] ì°¸ê°€ìëŠ” ëª¨ë¸ í•™ìŠµì— í…ŒìŠ¤íŠ¸ì…‹ì„ í™œìš©í•˜ê±°ë‚˜, í…ŒìŠ¤íŠ¸ì…‹ì˜ ì •ë³´ë¥¼ í•™ìŠµì— í™œìš©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

- [ë°ì´í„° ì¦ê°•] Train/Dev ë°ì´í„°ì— í•œí•´ ì¦ê°• ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ë§Œ ê¸°ìˆ ì /í†µê³„ì  ê·¼ê±°ê°€ ì¡´ì¬í•´ì•¼í•˜ë©°, ëˆ„êµ¬ë‚˜ ë™ì¼í•œ ì¦ê°• ê²°ê³¼ë¬¼ì„ ìƒì„±í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

- [ë°ì´í„°ì…‹ ì €ì‘ê¶Œ] ëŒ€íšŒ ë°ì´í„°ì…‹ì€ 'ìº í”„ êµìœ¡ìš© ë¼ì´ì„ ìŠ¤' ì•„ë˜ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ì €ì‘ê¶Œ ê´€ë ¨ ì„¸ë¶€ ë‚´ìš©ì€ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ê³µì§€ì‚¬í•­ì„ ë°˜ë“œì‹œ ì°¸ê³  í•´ì£¼ì„¸ìš”.

AI Stages ëŒ€íšŒ ê³µí†µì‚¬í•­

- [Private Sharing ê¸ˆì§€] ë¹„ê³µê°œì ìœ¼ë¡œ ë‹¤ë¥¸ íŒ€ê³¼ ì½”ë“œ í˜¹ì€ ë°ì´í„°ë¥¼ ê³µìœ í•˜ëŠ” ê²ƒì€ í—ˆìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
  ì½”ë“œ ê³µìœ ëŠ” ë°˜ë“œì‹œ ëŒ€íšŒ ê²Œì‹œíŒì„ í†µí•´ ê³µê°œì ìœ¼ë¡œ ì§„í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

- [ìµœì¢… ê²°ê³¼ ê²€ì¦ ì ˆì°¨] ë¦¬ë”ë³´ë“œ ìƒìœ„ê¶Œ ëŒ€ìƒìœ¼ë¡œì¶”í›„ ì½”ë“œ ê²€ìˆ˜ê°€ í•„ìš”í•œ ëŒ€ìƒìœ¼ë¡œ íŒë‹¨ë  ê²½ìš° ê°œë³„ ì—°ë½ì„ í†µí•´ ì¶”ê°€ ê²€ìˆ˜ ì ˆì°¨ë¥¼ ì•ˆë‚´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ê²°ê³¼ê°€ ì¬í˜„ë  ìˆ˜ ìˆë„ë¡ ìµœì¢… ì½”ë“œë¥¼ ì •ë¦¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤. ë¶€ì •í–‰ìœ„ê°€ ì˜ì‹¬ë  ê²½ìš°ì—ëŠ” ê²°ê³¼ ì¬í˜„ì„ ìš”êµ¬í•  ìˆ˜ ìˆìœ¼ë©°, ì¬í˜„ì´ ì–´ë ¤ìš¸ ê²½ìš° ë¦¬ë”ë³´ë“œ ìˆœìœ„í‘œì—ì„œ ì œì™¸ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- [ê³µìœ  ë¬¸í™”] ê³µê°œì ìœ¼ë¡œ í† ë¡  ê²Œì‹œíŒì„ í†µí•´ ëª¨ë¸ë§ì— ëŒ€í•œ ì•„ì´ë””ì–´ í˜¹ì€ ì‘ì„±í•œ ì½”ë“œë¥¼ ê³µìœ í•˜ì‹¤ ê²ƒì„ ê¶Œì¥ ë“œë¦½ë‹ˆë‹¤. ê³µìœ  ë¬¸í™”ë¥¼ í†µí•´ì„œ ë”ìš± ë›°ì–´ë‚œ ëª¨ë¸ì„ ëŒ€íšŒ ì°¸ê°€ì ë¶„ë“¤ê³¼ ê°™ì´ ê°œë°œí•´ ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤.

- [ëŒ€íšŒ ì°¸ê°€ ê¸°ë³¸ ë§¤ë„ˆ] ì¢‹ì€ ëŒ€íšŒ ë¬¸í™” ì •ì°©ì„ ìœ„í•´ ì•„ë˜ ëª…ì‹œëœ í–‰ìœ„ëŠ” ì§€ì–‘í•©ë‹ˆë‹¤.

- ëŒ€íšŒ ì¢…ë£Œë¥¼ ì•ë‘ê³  (3ì¼ ì „) ë†’ì€ ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ì „ì²´ ì½”ë“œë¥¼ ê³µìœ í•˜ëŠ” í–‰ìœ„

- íƒ€ ì°¸ê°€ìì™€ í† ë¡ ì´ ì•„ë‹Œ ë‹¨ìˆœ ì†”ë£¨ì…˜ì„ ìºë‚´ëŠ” í–‰ìœ„

**

Â Â **

ì£¼ìš” ë°ì´í„°ëŠ” csv í˜•íƒœë¡œ ì œê³µë˜ë©° ì£¼ì–´ì§€ëŠ” ë‘ ë¬¸ì¥ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ìµœì¢… ëª©í‘œì…ë‹ˆë‹¤. ë°ì´í„°ì…‹ì˜ train/dev/test ì€ 85/5/10ì˜ ë¹„ìœ¨ë¡œ ë‚˜ëˆ„ì–´ì¡ŒìŠµë‹ˆë‹¤.

ì•„ë˜ëŠ” ê° ë°ì´í„°ì˜ ê°œìˆ˜ì™€ Label ì ìˆ˜ì˜ ì˜ë¯¸ì…ë‹ˆë‹¤.

- ì´ ë°ì´í„° ê°œìˆ˜ : 10,974 ë¬¸ì¥ ìŒ

- Train ë°ì´í„° ê°œìˆ˜: 9,324

- Test ë°ì´ì„œ ê°œìˆ˜: 1,100

- Dev ë°ì´í„° ê°œìˆ˜: 550

- Label ì ìˆ˜: 0 ~ 5ì‚¬ì´ì˜ ì‹¤ìˆ˜

- 5ì  : ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì´ ë™ì¼í•˜ë©°, ë¶€ê°€ì ì¸ ë‚´ìš©ë“¤ë„ ë™ì¼í•¨

- 4ì  : ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì´ ë™ë“±í•˜ë©°, ë¶€ê°€ì ì¸ ë‚´ìš©ì—ì„œëŠ” ë¯¸ë¯¸í•œ ì°¨ì´ê°€ ìˆìŒ

- 3ì  : ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì€ ëŒ€ëµì ìœ¼ë¡œ ë™ë“±í•˜ì§€ë§Œ, ë¶€ê°€ì ì¸ ë‚´ìš©ì— ë¬´ì‹œí•˜ê¸° ì–´ë ¤ìš´ ì°¨ì´ê°€ ìˆìŒ

- 2ì  : ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì€ ë™ë“±í•˜ì§€ ì•Šì§€ë§Œ, ëª‡ ê°€ì§€ ë¶€ê°€ì ì¸ ë‚´ìš©ì„ ê³µìœ í•¨

- 1ì  : ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì€ ë™ë“±í•˜ì§€ ì•Šì§€ë§Œ, ë¹„ìŠ·í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŒ

- 0ì  : ë‘ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì´ ë™ë“±í•˜ì§€ ì•Šê³ , ë¶€ê°€ì ì¸ ë‚´ìš©ì—ì„œë„ ê³µí†µì ì´ ì—†ìŒ

ê° ë°ì´í„°ë³„ Label ì ìˆ˜ëŠ” ì—¬ëŸ¬ëª…ì˜ ì‚¬ëŒì´ ìœ„ì˜ ì ìˆ˜ ê¸°ì¤€ì„ í† ëŒ€ë¡œ í‰ê°€í•œ ë‘ ë¬¸ì¥ê°„ì˜ ì ìˆ˜ë¥¼ í‰ê· ë‚¸ ê°’ì…ë‹ˆë‹¤. ë‘ ë¬¸ì¥ê°„ì˜ ìœ ì‚¬ë„ëŠ” ì‚¬ëŒë§ˆë‹¤ ë‹¤ë¥´ê²Œ í‰ê°€ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ì—¬ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.

ë°ì´í„° êµ¬ì¡°ì¸ ê° column ë³„ ì„¤ëª…ì…ë‹ˆë‹¤. ì˜ˆì¸¡ íƒ€ê²Ÿ ê°’ì€ 0 ~ 5ì  ì‚¬ì´ì˜ ê°’ì…ë‹ˆë‹¤. ë°ì´í„°ëŠ” idë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**

**![](https://lh5.googleusercontent.com/fmyJjwGukIcg2MIVXKFI5tz68X6M1OVF0qUDuTLFzBkWNpc3L1NUi817FtQxvFC28Q6fa5RPis4dESiM7Gglas6UopR7m7WjkX4lyvHIQgNAmbeDun7ldx_LA1buNMnyRnHmWeiC-BDy-cldqS1rddQ)**

**

- id (ë¬¸ìì—´) : ë¬¸ì¥ ê³ ìœ  IDì…ë‹ˆë‹¤. ë°ì´í„°ì˜ ì´ë¦„ê³¼ ë²„ì „, train/dev/testê°€ ì í˜€ ìˆìŠµë‹ˆë‹¤.

- source (ë¬¸ìì—´) : ë¬¸ì¥ì˜ ì¶œì²˜ë¡œ ì´ 3ê°€ì§€ source ê°€ ìˆìŠµë‹ˆë‹¤.

- petition (êµ­ë¯¼ì²­ì› ê²Œì‹œíŒ ì œëª© ë°ì´í„°)

- NSMC (ë„¤ì´ë²„ ì˜í™” ê°ì„± ë¶„ì„ ì½”í¼ìŠ¤, Naver Sentiment Movie Corpus)

- slack (ì—…ìŠ¤í…Œì´ì§€(Upstage) ìŠ¬ë™ ë°ì´í„°)

- sentence1 (ë¬¸ìì—´) : ë¬¸ì¥ ìŒì˜ ì²«ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤.

- sentence2 (ë¬¸ìì—´) : ë¬¸ì¥ ìŒì˜ ë‘ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤.

- label : ë¬¸ì¥ ìŒì— ëŒ€í•œ ìœ ì‚¬ë„ë¡œ 0~5 ì ìœ¼ë¡œ ì†Œìˆ˜ ì²«ì§¸ ìë¦¬ê¹Œì§€ ìˆìŠµë‹ˆë‹¤.

- binary-label : ë¬¸ì¥ ìŒì— ëŒ€í•œ ìœ ì‚¬ë„ê°€ 2ì  ì´í•˜ì¸ ê²½ìš°ì—” 0ìœ¼ë¡œ, 3ì  ì´ìƒì¸ ê²½ìš°ì—” 1ë¡œ ë³€í™˜í•œ binary label ì…ë‹ˆë‹¤.

ì œê³µë˜ëŠ” ë°ì´í„°ëŠ” train.csv / dev.csv / test.csv / sample_submission.csvì˜ 4ê°œì˜ íŒŒì¼ë¡œ ë˜ì–´ìˆìœ¼ë©° train.csv, dev.csv íŒŒì¼ë¡œ í•™ìŠµí•˜ì—¬ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

**

**

- id (ë¬¸ìì—´) : ë¬¸ì¥ ê³ ìœ  IDì…ë‹ˆë‹¤. ë°ì´í„°ì˜ ì´ë¦„ê³¼ ë²„ì „, train/dev/testê°€ ì í˜€ ìˆìŠµë‹ˆë‹¤.

- source (ë¬¸ìì—´) : ë¬¸ì¥ì˜ ì¶œì²˜ë¡œ ì´ 3ê°€ì§€ source ê°€ ìˆìŠµë‹ˆë‹¤.

- petition (êµ­ë¯¼ì²­ì› ê²Œì‹œíŒ ì œëª© ë°ì´í„°)

- NSMC (ë„¤ì´ë²„ ì˜í™” ê°ì„± ë¶„ì„ ì½”í¼ìŠ¤, Naver Sentiment Movie Corpus)

- slack (ì—…ìŠ¤í…Œì´ì§€(Upstage) ìŠ¬ë™ ë°ì´í„°)

- sentence1 (ë¬¸ìì—´) : ë¬¸ì¥ ìŒì˜ ì²«ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤.

- sentence2 (ë¬¸ìì—´) : ë¬¸ì¥ ìŒì˜ ë‘ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤.

- label : ë¬¸ì¥ ìŒì— ëŒ€í•œ ìœ ì‚¬ë„ë¡œ 0~5 ì ìœ¼ë¡œ ì†Œìˆ˜ ì²«ì§¸ ìë¦¬ê¹Œì§€ ìˆìŠµë‹ˆë‹¤.

- binary-label : ë¬¸ì¥ ìŒì— ëŒ€í•œ ìœ ì‚¬ë„ê°€ 2ì  ì´í•˜ì¸ ê²½ìš°ì—” 0ìœ¼ë¡œ, 3ì  ì´ìƒì¸ ê²½ìš°ì—” 1ë¡œ ë³€í™˜í•œ binary label ì…ë‹ˆë‹¤.

ì œê³µë˜ëŠ” ë°ì´í„°ëŠ” train.csv / dev.csv / test.csv / sample_submission.csvì˜ 4ê°œì˜ íŒŒì¼ë¡œ ë˜ì–´ìˆìœ¼ë©° train.csv, dev.csv íŒŒì¼ë¡œ í•™ìŠµí•˜ì—¬ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

**

**

![](https://lh6.googleusercontent.com/f1yvqoNZwuLLHj_uSWs36M1DeANRBkWZwDcdQkr4r3vpsMaso4WmmTmNgu3218TNWdeWkUd-VgyMQsqaNojd-faJPQhFMzpODntPgZ9zCO1SgZONdO0wkOO6ainnvZX6NT7s9-pTaW7eh_0ZDTJ_lGA)**

**ì—¬ëŸ¬ë¶„ì˜ ê³¼ì œëŠ” í•™ìŠµëœ ëª¨ë¸ë¡œ test.csv íŒŒì¼ì„ í™œìš©í•˜ì—¬ ì¶œë ¥ë˜ëŠ” ì˜ˆì¸¡ ê°’ì„ ì œì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì œì¶œ íŒŒì¼ì€ sample_submission.csv ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. sample_submission.csv íŒŒì¼ì˜ êµ¬ì¡°ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ idê°€ ìˆì–´ì•¼ í•˜ê³  target ì— í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ idì™€ ë§ê²Œ ì˜ˆì¸¡ëœ 0~5ì ì˜ label ê°’ì´ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.**

**![](https://lh3.googleusercontent.com/NJCFJUCXEULWV_AGPlw8i217tGTw34dEm5sEWIy0kxGWLw5V9XLwizMEzFN04zgOKZFtrzGju0XdNRfWEhs5KIOii54h8P_6ufRDJKMBU7i8BxAqyQGONLc_qCjA9ObtG1yh528D-_R_Vio81k7K9nA)**

**

í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì€ í•™ìŠµ ë°ì´í„°ì…‹ê³¼ ë‹¤ë¥´ê²Œ label ê³¼ binary-labelì´ ì—†ìŠµë‹ˆë‹¤.

â”œâ”€code.tar.gz

â”‚Â  â”‚Â  train.py

â”‚Â  â”‚Â  inference.py

â”‚Â  â”‚Â  requirements.txt

ì½”ë“œ íŒŒì¼ì€ [train.py](http://train.py), [inference.py](http://inference.py), requirements.txt ì„¸ ê°€ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- train.py : ë°ì´í„° í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

- inference.py : í•™ìŠµëœ ëª¨ë¸ë¡œ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

- requirements.txt : train.pyì™€ inference.pyë¥¼ ì‹¤í–‰í•˜ëŠ”ë° í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ ë‹´ê²¨ìˆëŠ” txt íŒŒì¼ì…ë‹ˆë‹¤.

ì½”ë“œëŠ” requirements.txt ì„¤ì¹˜, [train.py](http://train.py), [inference.py](http://inference.py) ìˆœì„œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

requirements.txt

- requirements.txtì—ëŠ” train.pyì™€ inference.pyë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤.

- train.pyì™€ [inference.py](http://inference.py) ì½”ë“œë¥¼ ì œì‘í•  ë•Œ í™œìš©ë˜ì—ˆë˜ ë²„ì „ì„ ëª…ì‹œí•˜ì˜€ìŠµë‹ˆë‹¤.

- pip install -r requirements.txtë¥¼ í†µí•´ requirements.txtì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ í•œë²ˆì— ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[train.py](http://train.py)

- train.pyëŠ” ë°ì´í„° í˜¸ì¶œ ë° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ Datasetê³¼ Dataloader, í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” Modelì´ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- ì½”ë“œëŠ” python3 train.py ë¥¼ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì„ í•™ìŠµ ëª¨ë¸ì€ [KLUE-bencmark](https://github.com/KLUE-benchmark/KLUE/blob/main/README.md)ì—ì„œ STS taskì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë˜ RoBERTaë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. í•™ìŠµì˜ í¸ì˜ë¥¼ ìœ„í•´ RoBERTa-smallì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- ArgumentParserì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¸ìê°€ ìˆìŠµë‹ˆë‹¤. :

- --model_nameì€ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ì„ í•™ìŠµ ëª¨ë¸ ì…ë‹ˆë‹¤.

- --batch_sizeëŠ” í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë°°ì¹˜ í¬ê¸° ì…ë‹ˆë‹¤.

- --max_epochì€ í•™ìŠµì˜ ì´ ì—í­ ì…ë‹ˆë‹¤.

- --shuffleì€ train ë°ì´í„°ì…‹ì˜ ìˆœì„œë¥¼ ì„ì„ì§€ ë§ì§€ ê²°ì •í•˜ëŠ” ì¸ìì…ë‹ˆë‹¤.

- --learning_rateëŠ” ëª¨ë¸ì˜ learning rateì…ë‹ˆë‹¤.

- --trainpath, devpath, testpath, predictpathëŠ” ê° ë°ì´í„°ì˜ ê²½ë¡œ ì…ë‹ˆë‹¤.

- ì½”ë“œ ì‹¤í–‰ ì‹œ ì›í•˜ëŠ” ì¸ìë¥¼ ë³€ê²½í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸ìê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ default ê°’ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ì‹¤í–‰í•©ë‹ˆë‹¤.

- ex) python3 train.py  
  â†’ model_name = klue/roberta-small

- ex) python3 train.py --model_name=klue/bert-base  
  â†’ model_name = klue/bert-base

- í•™ìŠµì€ ì—í­ë‹¹ ì•½ 3ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.

- í•™ìŠµì´ ì™„ë£Œë˜ë©´, torch.save(model, 'model.pt') ë¥¼ í†µí•´ ì„ í•™ìŠµëœ ëª¨ë¸ì„ model.ptë¼ëŠ” íŒŒì¼ë¡œ ì €ì¥í•˜ê²Œ ë©ë‹ˆë‹¤.

[inference.py](http://inference.py)

- inference.pyëŠ” train.pyì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ë¬¸ì œ ë°ì´í„°ì…‹ì„ ì˜ˆì¸¡í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

- ì½”ë“œëŠ” python3 inference.py ë¥¼ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- Inference partì˜ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ :
1. train.pyì—ì„œ ì €ì¥ëœ model.ptë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.

2. ì˜ˆì¸¡ëœ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ì— ë§ê²Œ ë³€ê²½í•˜ì—¬ ì¤€ë¹„í•©ë‹ˆë‹¤.

3. sample_submission.csvë¥¼ ë¶ˆëŸ¬ì™€ targetë§Œ ì˜ˆì¸¡ëœ ê²°ê³¼ë¡œ ë³€ê²½í•˜ê³  output.csvë¡œ ì €ì¥í•©ë‹ˆë‹¤.
- ì½”ë“œ ì‹¤í–‰ì´ ëë‚˜ë©´ output.csvë¼ëŠ” ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ê³  ë¦¬ë”ë³´ë“œ

### Links

Download Data Link

https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000236/data/data.tar.gz

Download Baseline Code Link

https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000236/data/code.tar.gz

### Leader Board

![](https://lh4.googleusercontent.com/8mQc-x-HbA7symQiQUJw9g1g1gEu6jXRZiHNdmpAOAkPBrwK9ZkEDw1KkeI058SAX3naUukrbX8MC7CSqTMr9Tg-7RwFxnPbByN72e-q-2MhmcVeckwoovSMs8nX5gsAQg96wKR4adE4_zz1NxpuZsY)

![](https://lh3.googleusercontent.com/J6QbprYyDeniErGlX4nk-7IQViN2LH24UQVJveYg7uATcI4gVSs5ChrYZhLs31pTKBHP2dKbYzVt5LPQP2xauh3dAWy84sNOtkiGkmgVcq714Qm5J_2_7ELEcc-k4eikaCbxsLySZt1HnmtOtuyePiw)

### ETC

[ê³µìœ ] STS ë¬¸ì œì—ì„œ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ 

Posted by ì •ì§€ìˆ˜

NLPì˜ ë§ì€ ë¬¸ì œë“¤ì„ í’€ ë•Œ, ëŒ€ì²´ë¡œ ìš°ë¦¬ëŠ” ì´ë¯¸ í†µìƒì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” í‰ê°€ ì§€í‘œê°€ ìˆìŠµë‹ˆë‹¤. ì•ì„œ ë°°ìš´ ê²ƒì²˜ëŸ¼, N21, N2N ë¬¸ì œì—ëŠ” f1-score, N2M ë¬¸ì œì—ëŠ” BLEU, ROGUE ë“±ì´ ìˆì£ .

STS ë¬¸ì œì—ì„œëŠ” ì™œ ë°°ì› ë˜ ì§€í‘œê°€ ì•„ë‹Œ, í”¼ì–´ìŠ¨ ìƒê´€ ê³„ìˆ˜(Pearson Correlation Coefficient)ë¼ëŠ” ì´ë¦„ë„ ì–´ë ¤ìš´ ì§€í‘œë¥¼ ì‚¬ìš©í• ê¹Œìš”?

ì´ ì§ˆë¬¸ì˜ ë‹µì€ â€œì¶œë ¥ í˜•íƒœâ€ì—ì„œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¼ë°˜ì ì¸ N21 ë¬¸ì œì—ëŠ” Classification ë¿ë§Œ ì•„ë‹ˆë¼, Regressionë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‘˜ ë‹¤ í•˜ë‚˜ì˜ ìˆ«ì, í˜¹ì€ ë¼ë²¨ì„ ì¶œë ¥í•œë‹¤ëŠ” ê³µí†µì ì´ ìˆì§€ë§Œ, classificationì€ ì •í•´ì§„ ë²”ìœ„ ë‚´ì—ì„œ ì¶œë ¥ì´ ìˆê³ , regressionì˜ ê²½ìš° ì‹¤ìˆ˜ ë²”ìœ„ì—ì„œ ìˆ˜ì¹˜ê°€ ì¶œë ¥ëœë‹¤ëŠ” ì°¨ì´ì ì´ ìˆìŠµë‹ˆë‹¤.

í”¼ì–´ìŠ¨ ìƒê´€ ê³„ìˆ˜ëŠ” ì´ëŸ° regressionìœ¼ë¡œ ì¶œë ¥ëœ ì˜ˆì¸¡ê°’ ì§‘í•©ê³¼ ì •ë‹µ ì§‘í•©ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

ë‘ ì§‘í•© x, yì— ëŒ€í•œ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

![](https://lh3.googleusercontent.com/zLDWsdlmdXgNwCUcTnAGPMLM2AwvHRczD44vqZbwxymYZIeBXYlCsb32n80LV9HtSi6JaYlTbGZ-bAcKlmcs_FGq3IXWkColD2SsDfokwM4bUmwI97cVyzLZLNKP_o3hWWY_Ovovh8l35_BE8yrY-vM)

rì€ í•­ìƒ -1~1 ì‚¬ì´ì˜ ì‹¤ìˆ˜ë¥¼ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ë‘ ì§‘í•© ì‚¬ì´ì˜ ì¼ì¹˜ë„ê°€ ë†’ë‹¤ê³  í‰ê°€í•˜ë©°, ìŒìˆ˜ì¼ ê²½ìš° ë‘ ì§‘í•©ì€ ì„œë¡œ ì—­ìˆ˜ ê´€ê³„ë¡œ í‰ê°€ë©ë‹ˆë‹¤. ëŒ€ì²´ë¡œ ì•„ë˜ í‘œì²˜ëŸ¼ ë”°ë¼ íŒë³„ë©ë‹ˆë‹¤.

![](https://lh5.googleusercontent.com/X6MbnmL6Gyru_fZ53myqHDcac3mF9K74aX5OIus2Z_G0hbHvXf5-Qk_cu9XZSRFE8d_zLSCgUCC8l5aHalTKwZnZbS9oLhA15CF35aIpcZ6ebPlhhusuwEJ8THJiioGQNcp4meY-d4psq5usYEZD43g)

Hinkle, D. E., Wiersma, W., & Jurs, S. G. (2003). Applied statistics for the behavioral sciencesÂ  (Vol. 663). Houghton Mifflin College Division.

í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ì—ë„ ë‹¨ì ì€ ìˆìŠµë‹ˆë‹¤. ë‘ ì§‘í•©ì˜ ì„ í˜•ì  ê´€ê³„ë§Œì„ ë³´ê¸° ë•Œë¬¸ì—, ì ìˆ˜ë¡œë§Œ íŒë‹¨í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ë‹¤ì–‘í•œ í˜•íƒœê°€ ì¡´ì¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.

![](https://lh5.googleusercontent.com/WC4jcYsp6bqL1xOP_xmZqa2HIwg4gy0kuKOMU__RRfpzi6OSMH8FifNCRXaDbWcKVqTdzUgp8Ky6rIWoXYiOdKqt1SX_UroJM43WEAaOr2tPO25VGpd1zDuI5UKaMCkHNpLCEXmDuKN8-HN0SKaSa90)

Anscombe, F. J. (1973). Graphs in statistical analysis. The american statistician , 27 (1), 17-21.

ì¼ë¡€ë¡œ, ìœ„ ê·¸ë¦¼ì€ ëª¨ë‘ 0.82ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ê°€ì§€ë‚˜ ëª¨ë‘ ìƒê¹€ìƒˆê°€ ë‹¤ë¦…ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ, ê²°ê³¼ ë¶„ì„ ì‹œ ê¼­ ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ë©° ëª¨ë¸ì˜ ì·¨ì•½ì ì„ í‰ê°€í•´ì•¼í•©ë‹ˆë‹¤.

ê·¸ë ‡ë‹¤ë©´, ì‹¤ì œ ì½”ë“œì—ì„œ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ì–´ë–»ê²Œ ì ìš©í• ê¹Œìš”?

ì´ë¯¸ ì—¬ëŸ¬ regression ë¬¸ì œì— ì‚¬ìš©ë˜ëŠ” ì§€í‘œì¸ ë§Œí¼, torchmetric ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì ìš© ì˜ˆì œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

import torch

from torchmetrics import PearsonCorrcoef

target = torch.tensor([5.0, 6.0, 0.0, 2.0])

preds = torch.tensor([2.5, 4.57, 2, 1.5])

pearson = PearsonCorrcoef()

pearson(preds, target)

í•´ë‹¹ ì˜ˆì œëŠ” ì‘ë™ í›„ 0.7692ì˜ ìƒê´€ ê³„ìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

![](https://lh3.googleusercontent.com/6xu6wLXx0XhiNOaubRGUohh28FnyH_KhvQa4f85c9J93kTfUofqRJ5RgvWn6lYowGKl7tWkxe3bOPGJIZnUNWdckv-tksoXSBrTZKyHWMi0ECyRhwyPs8kVz4a1agCQayFYTS2a8Ny_L3CMvo0XPExQ)

í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ëŠ” ë‘ í…ì„œì˜ shapeì´ ë™ì¼í•´ì•¼í•œë‹¤ëŠ” ì ì„ ì£¼ì˜í•˜ì—¬ ì ìš©í•´ì£¼ì„¸ìš”!

ì°¸ê³  ì‚¬ì´íŠ¸

https://torchmetrics.readthedocs.io/en/latest/regression/pearson_corr_coef.html**

[ê³µìœ ] ê±°ì¸ì˜ ì–´ê¹¨ì— ì˜¬ë¼ì„œê¸°

Posted by í™©íƒœìš±_ì¡°êµ

2023.03.28.18:07

ì»´í“¨í„°ê³µí•™ì€ ë‹¤ë¥¸ í•™ë¬¸ì— ë¹„í•´ ë³€í™” ì†ë„ê°€ ë¹ ë¥¸ í¸ì¸ë°, ê·¸ ì¤‘ AIëŠ” ìœ ë… ë” ë¹ ë¥¸í¸ì…ë‹ˆë‹¤. ìµœì‹  ê¸°ìˆ ì„ ì°¾ëŠ” ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•ì€ ë…¼ë¬¸ì„ ë³´ëŠ” ê²ƒì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ ë‹¤ë‹¬ì´ state of the art(SOTA, ìµœê³ ì„±ëŠ¥) ëª¨ë¸ì´ ê°±ì‹ ë˜ëŠ” ìƒí™©ì´ë¼, ìµœì‹  ë…¼ë¬¸ì„ ì«“ì•„ê°€ê¸°ê°€ ìƒë‹¹íˆ ë²„ê²ìŠµë‹ˆë‹¤.

ë°˜ë©´ì— AIë¼ëŠ” íŠ¹ìˆ˜í•œ í•™ë¬¸ì´ë¼ì„œ ìµœì‹  ê¸°ìˆ ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.

1. íƒœìŠ¤í¬ ë° ë°ì´í„°ì…‹ë³„ë¡œ SOTAë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” [PapersWithCode](https://paperswithcode.com/)

2. ì„¸ê³„ ìµœëŒ€ì˜ ë°ì´í„° ê³¼í•™ì ì»¤ë®¤ë‹ˆí‹° [Kaggle](https://www.kaggle.com/)

3. êµ­ë‚´ì˜ AI ê²½ì§„ëŒ€íšŒ í”Œë«í¼ [Dacon](https://dacon.io/), [AIFactory](https://aifactory.space/)
- [PapersWithCode](https://paperswithcode.com/)ëŠ” íƒœìŠ¤í¬ì™€ ë°ì´í„°ì…‹ë³„ë¡œ SOTA ëª¨ë¸ íˆìŠ¤í† ë¦¬ì™€ í•´ë‹¹ ëª¨ë¸ë“¤ì˜ ë…¼ë¬¸, ê¹ƒí—ˆë¸Œ ë§í¬ë¥¼ ëª¨ì•„ë‘” ì›¹ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤. ì´ê³³ì„ í†µí•´ í˜„ì¬ ìµœì‹  íŠ¸ë Œë“œì™€ ì½”ë“œê¹Œì§€ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
  ![](https://lh6.googleusercontent.com/e3tGqpbcpyjjrmza4B9abS2v-t9BQg8Farcvlft3zEYG2mkVIKJm7du8O0QaGxfgdd6WFCWa4dc6GKfa-Q99iH6D8qNgSHc3l2oDdtr5Sb44KbW-xPgcFhLhFJTfJhBWcpBMO0wV8aDso66Eb2RPIT8)  

- [Kaggle](https://www.kaggle.com/)ì€ AI ê²½ì§„ëŒ€íšŒì™€ ì»¤ë®¤ë‹ˆí‹°ê°€ ì ì ˆíˆ ìœµí•©ë˜ì–´ìˆìŠµë‹ˆë‹¤. ì§‘ë‹¨ì§€ì„±ì„ í†µí•œ ë¬¸ì œí•´ê²°ì„ í‘œë°©í•˜ê¸° ë•Œë¬¸ì— Code, Discussionsì— ìˆ˜ë§ì€ ì •ë³´ê°€ ê³µìœ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ ìƒê¸ˆì´ ê±¸ë ¤ìˆëŠ” Competitionsì—ë„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ìê°€ ìˆ˜í–‰í•œ EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„)ê²°ê³¼ë‚˜ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ ì½”ë“œë¥¼ ê³µìœ í•˜ëŠ” ìµœì‹  ê¸°ìˆ ì„ ë¹ ë¥´ê²Œ ì ‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
  ![](https://lh4.googleusercontent.com/1D84fP0EqtrMTxlj2jkyT03GE5An0e9D2imyMgEzxy5DZ8PbEbHvWpYenc965YO0ovWsmnEQYxq3fFKJVDNzPgnXvEofEziLhTnmrLWgikVuv5unzVOLHcdnCQEDdwJqefMHCaKWOooH2iXLFh9w4W0)  

- [Dacon](https://dacon.io/)ê³¼ [AIFactory](https://aifactory.space/)ëŠ” êµ­ë‚´ AI ê²½ì§„ëŒ€íšŒë¡œ, Kaggleì— ë¹„í•˜ë©´ ì •ë³´ì˜ ê³µìœ ëŸ‰ì€ í˜„ì €íˆ ë‚®ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëŒ€íšŒë§ˆë‹¤ ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œë¥¼ í•¨ê»˜ ê³µê°œí•˜ëŠ” í¸ì´ë©°, ìˆ˜ìƒì‘ì˜ ì½”ë“œë„ ê³µê°œí•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤.  
  ![](https://lh4.googleusercontent.com/HlrRRyNkJm8dDwTLjXtpSpCj-sj5Q6ZpI_ubhCHnQGRsuZSyNEfCrslR2sGi9Q2W7DcXVYr2oWKJmt4DsviMXTC3WzIyrsVhLMz23RuZLnubSmLFAVg1SA3bc2k-wl1bo54JsIiSC-BrisLUy31kkdI)

ì´ë ‡ê²Œ ìµœì‹  ê¸°ìˆ ì„ ì ‘í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë“¤ì„ ì˜ í™œìš©í•˜ê¸° ìœ„í•œ íŒì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

1. [PapersWithCode](https://paperswithcode.com/)ë¥¼ í†µí•´ ìµœì‹  íŠ¸ëœë“œ ëª¨ë¸ê³¼ ë…¼ë¬¸ì°¸ê³ í•˜ê¸°

2. [Kaggle](https://www.kaggle.com/)ì— ìˆëŠ” ìœ ì‚¬ íƒœìŠ¤í¬ ë° ë°ì´í„°ì…‹ì„ ì°¾ì•„ ìµœì‹  ê¸°ìˆ (EDA, ì•™ìƒë¸”, ëª¨ë¸ ë“±) ì•Œì•„ë³´ê¸°

3. 1ë²ˆê³¼ 2ë²ˆì´ ì–´ë µë‹¤ë©´ [Dacon](https://dacon.io/)ê³¼ [AIFactory](https://aifactory.space/)ì—ì„œ ìœ ì‚¬ íƒœìŠ¤í¬ ë° ë°ì´í„°ì…‹ì„ ì°¾ì•„ ë² ì´ìŠ¤ë¼ì¸ì½”ë“œì™€ ê³µê°œëœ ì½”ë“œ í™œìš©í•˜ê¸°

ì´ëŸ¬í•œ ë°©ë²•ë§Œ ì˜ í™œìš©í•˜ì‹œë©´ ì‰½ê²Œ ìƒìœ„ê¶Œì— ê·¼ì ‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ì§ê¹Œì§€ êµ­ë‚´ì—ì„œëŠ” ëŒ€íšŒì—ì„œ ì •ë³´ êµë¥˜ê°€ ì ì€ í¸ì¸ë°, ì„œë¡œ ë°œì „í•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ë§ì•„ì§€ê¸¸ ë°”ëë‹ˆë‹¤!

[ê³µìœ ] Huggingface 200% í™œìš©í•˜ê¸°

Posted by ë‚¨ê¶í˜_ì¡°êµ

2023.03.29.13:48

Â 

ì´ë²ˆ í† ë¡ ì—ì„œ Huggingfaceì— ëŒ€í•´ ì•Œì•„ë´…ì‹œë‹¤.

1. Huggingface ë€ ë¬´ì—‡ì¸ê°€?

HuggingFaceëŠ” ë‹¤ìŒì„ ì œê³µí•˜ëŠ” ì»¤ë®¤ë‹ˆí‹° ë° Data Science í”Œë«í¼ì…ë‹ˆë‹¤.

![](https://lh6.googleusercontent.com/uXv8sYf3vHZN4kIj3O5BrgSmPhU1CTPIeQD5Kov-ITrNUCVKGvtKSR-rDKmHoKsdx-803RQi320KUsHPO9PiYQmv_QLxV5tLJzHlV76D8KGHrVhE41SAMtGwSru3MSa8DlJasfEel_QlLHhlCkyHxyE)

- ì‚¬ìš©ìê°€ ì˜¤í”ˆ ì†ŒìŠ¤(OS) ì½”ë“œ ë° ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ ML ëª¨ë¸ì„ êµ¬ì¶•, êµìœ¡ ë° ë°°í¬í•  ìˆ˜ ìˆëŠ” ë„êµ¬

- ê´‘ë²”ìœ„í•œ Data Scientist, Researcher ë° ML ì—”ì§€ë‹ˆì–´ ì»¤ë®¤ë‹ˆí‹°ê°€ í•¨ê»˜ ëª¨ì—¬ ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•˜ê³ , ì§€ì›ì„ ë°›ê³ , ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê³³

- JAX, PyTorch ë° TensorFlowë¥¼ ì§€ì›í•˜ëŠ” ìµœì²¨ë‹¨ ê¸°ê³„ í•™ìŠµ

- ì°¸ê³  ë§í¬

- [GitHub - huggingface/transformers: ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.](https://github.com/huggingface/transformers)

- ì¼ë°˜ì ì¸ [layer.py](http://layer.py/), [model.py](http://model.py/) ëŠ” transformer.models ë¡œ ëŒ€ì‘í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

transformers.models

- íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ ë‹¤ì–‘í•œ ëª¨ë¸ì„ pytorch, tensorflowë¡œ ê°ê° êµ¬í˜„í•´ ë†“ì€ ëª¨ë“ˆì…ë‹ˆë‹¤.

- ê° ëª¨ë¸ì— ë§ëŠ” tokenizer ë„ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
1. Huggingface Tasks

HuggingFaceëŠ” í…ìŠ¤íŠ¸, ì‹œê° ë° ì˜¤ë””ì˜¤ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì–‘ì‹ì— ëŒ€í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ìˆ˜ì²œ ê°œì˜ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ëª¨ë¸ì€ ë‹¤ìŒì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://lh4.googleusercontent.com/CqoH4o9KxNV2qkYkNQ6HN2_fQkuclPqmtc-RHy3sctFhFRbKXl9_MsxtXZJ0fns-hh5i369I_EfIxNfCvYUyOGvmX3xFOLO6kqei8pyRYG_GnGM2vdEFEFfJbJo-cXkwuchWyzaedLB-iw2EQD9aWtc)

- 100ê°œ ì´ìƒì˜ ì–¸ì–´ë¡œ ëœ í…ìŠ¤íŠ¸ ë¶„ë¥˜, ì •ë³´ ì¶”ì¶œ, ì§ˆë¬¸ ë‹µë³€, ìš”ì•½, ë²ˆì—­, í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ê°™ì€ ì‘ì—…ì„ ìœ„í•œ í…ìŠ¤íŠ¸

- ì´ë¯¸ì§€ë“¤ë¡œ ëœ ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ ê°ì§€ ë° ì„¸ë¶„í™”ì™€ ê°™ì€ ì‘ì—…ë“¤

- ì˜¤ë””ì˜¤ë¡œ ëœ ìŒì„± ì¸ì‹ ë° ì˜¤ë””ì˜¤ ë¶„ë¥˜ì™€ ê°™ì€ ì‘ì—…ë“¤

- ë˜í•œ í…Œì´ë¸” ì§ˆë¬¸ ì‘ë‹µ, ê´‘í•™ ë¬¸ì ì¸ì‹, ìŠ¤ìº” ë¬¸ì„œì—ì„œ ì •ë³´ ì¶”ì¶œ, ë¹„ë””ì˜¤ ë¶„ë¥˜ ë° ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µê³¼ ê°™ì´ ì—¬ëŸ¬ ì‘ì—…ì„ ê²°í•©í•˜ì—¬ ìˆ˜í–‰ ê°€ëŠ¥

TransformersëŠ” ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ ë‹¤ìš´ë¡œë“œ ë° ì‚¬ìš©í•˜ê³ , ìì²´ ë°ì´í„°ì—ì„œ ë¯¸ì„¸ ì¡°ì •í•œ ë‹¤ìŒ, ëª¨ë¸ í—ˆë¸Œ ì˜ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ í•  ìˆ˜ ìˆëŠ” APIë¥¼ ì œê³µí•©ë‹ˆë‹¤ .

2. Huggingface ëª¨ë¸

https://huggingface.co/models

HuggingFaceëŠ” ë‹¤ì–‘í•œ Transformer ëª¨ë¸ë“¤ì´ ë°°í¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì˜ ëª©ì ì„ ìœ„í•œ ëª¨ë¸ì„ ì°¾ê³  ìì‹ ì˜ ì½”ë“œì— ì ìš©í•´ ë³´ëŠ” ê²ƒì´ ì‰½ê³  ê°„í¸í•˜ê²Œ ë˜ì–´ìˆì–´ìš”.

Tasks, ë¼ì´ë¸ŒëŸ¬ë¦¬, ë°ì´í„°ì„¸íŠ¸ ì¢…ë¥˜, êµ­ê°€ì–¸ì–´ë“± ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìœ¼ë©° ì°¾ì€ ëª¨ë¸ì˜ ì´ë¦„ì„ í†µí•´ ì•„ë˜ì™€ ê°™ì´ ìì‹ ì˜ ì½”ë“œì— ëª¨ë¸ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

from transformers import AutoTokenizer, AutoModel

model = AutoModel.from_pretrained("bert-base-cased")

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")

AutoConfigë¥¼ í†µí•´ ëª¨ë¸ì˜ êµ¬ì„±ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìœ¼ë©° ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì˜ êµ¬ì„±ì„ ë¶ˆëŸ¬ì™€ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

from transformers import AutoConfig

# huggingface.co ì™€ cacheì—ì„œ ëª¨ë¸ êµ¬ì„± ë‹¤ìš´ë¡œë“œ

config = AutoConfig.from_pretrained("bert-base-uncased")

# í•´ë‹¹ ê²½ë¡œì— ìˆëŠ” ëª¨ë¸ êµ¬ì„± íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°

config = AutoConfig.frompretrained("./test/bertsavedmodel/myconfiguration.json")

# í•™ìŠµëœ ëª¨ë¸ì˜ êµ¬ì„±ì˜ ì„¤ì • ìˆ˜ì •í•˜ê¸°

config, unusedkwargs = AutoConfig.frompretrained("bert-base-uncased", outputattentions=True, foo=False, returnunused_kwargs=True)

print(config.output_attentions) # True

print(unused_kwargs) # {'foo': False}

ê·¸ì™¸ Tokenizer, ì‚¬ì „í•™ìŠµì„ ìœ„í•œ ëª¨ë¸ API, íŠ¹ì • taskë¥¼ ìœ„í•œ ëª¨ë¸ APIì™€ ê°™ì€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ì„ ì œê³µí•˜ë‹ˆ ì•„ë˜ ë§í¬ì—ì„œ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•´ë³´ì„¸ìš”!

https://huggingface.co/docs/transformers/model_doc/auto

3. Huggingface ë°ì´í„°

[Hugging Face â€“ The AI community building the future.](https://huggingface.co/datasets)

HuggingFaceëŠ” ì—¬ëŸ¬ ì‘ì—…ë“¤ì„ ìœ„í•œ ë°ì´í„°ë“¤ì´ ë°°í¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìì—°ì–´, ì˜¤ë””ì˜¤, ì´ë¯¸ì§€ ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë“¤ê³¼ ëª¨ë¸ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë“¤ë„ ì œê³µí•˜ë‹ˆ ìì‹ ì˜ ëª¨ë¸ì„ ì‰½ê²Œ í‰ê°€í•  ìˆ˜ ìˆì–´ìš”!

ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ì›í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ìˆê³  ë‹¤ë¥¸ ì‚¬ëŒì´ ë§ì´ ì°¾ëŠ” ë°ì´í„°ë‚˜ ìµœì‹  ë°ì´í„°ë¥¼ ì°¾ì•„ ìì‹ ì˜ ì½”ë“œì— ì ìš©í•˜ê¸° ì‰½ê²Œ ë˜ì–´ìˆìŠµë‹ˆë‹¤.

ë˜í•œ ë°ì´í„°ë¥¼ ì„ íƒí•˜ë©´ ì–´ë–¤ ëª¨ë¸ë“¤ì´ ì‚¬ìš©ì„ í•´ë³´ì•˜ëŠ”ì§€, ì–´ë–¤ êµ¬ì¡°ì¸ì§€, ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ë“±ì˜ ì •ë³´ê°€ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬ë˜ì–´ ë¹ ë¥´ê²Œ ë°ì´í„°ë¥¼ íŒŒì•…í•˜ê³  í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://lh3.googleusercontent.com/zpdzBcVO0FmPrRXYmA3W8Fau0BsVWFv0qr8MDwLLkDmTUIpKJ3y8BaLdDBwV0oHwHk2X9nmXamMbdVUwE2N7JOUviCo1sj9PmXTm75b5SyYx2kQg2pwDVTRqCjGJouevzTEQaSU2yoI5bMj7jY4-x90)

ê·¸ë¦¬ê³  ë°ì´í„° ë˜í•œ ëª¨ë¸ì²˜ëŸ¼ ê°„í¸í•˜ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆì–´ìš”. loaddatasetbuilderë¥¼ í†µí•´ ë°ì´í„°ì— ëŒ€í•œ ì„¤ëª…ê³¼ êµ¬ì¡°ë¥¼ ë³¼ ìˆ˜ ìˆìœ¼ë©° load_datasetë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ì—¬ëŸ¬ë¶„ì˜ ì½”ë“œì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

from datasets import load_dataset_builder

dsbuilder = loaddatasetbuilder("rottentomatoes")

# ë°ì´í„°ì˜ ì„¤ëª…

ds_builder.info.description

# ë°ì´í„°ì˜ íŠ¹ì§•

ds_builder.info.features

# {'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None), 'text': Value(dtype='string', id=None)}

from datasets import load_dataset

dataset = load_dataset("rottentomatoes")

'''

DatasetDict({

Â Â Â Â train: Dataset({

Â Â Â Â Â Â Â Â features: ['text', 'label'],

Â Â Â Â Â Â Â Â num_rows: 8530

Â Â Â Â })

Â Â Â Â validation: Dataset({

Â Â Â Â Â Â Â Â features: ['text', 'label'],

Â Â Â Â Â Â Â Â num_rows: 1066

Â Â Â Â })

Â Â Â Â test: Dataset({

Â Â Â Â Â Â Â Â features: ['text', 'label'],

Â Â Â Â Â Â Â Â num_rows: 1066

Â Â Â Â })

})

'''

dataset = loaddataset("rottentomatoes", split="train")

'''

Dataset({

Â Â Â Â features: ['text', 'label'],

Â Â Â Â num_rows: 8530

})

'''

ì•„ë˜ ë§í¬ë¥¼ í†µí•´ ë” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ë©´ íŠœí† ë¦¬ì–¼ì„ ì§„í–‰í•´ë³´ì„¸ìš”.

[Overview](https://huggingface.co/docs/datasets/tutorial)

ì§€ê¸ˆê¹Œì§€ Huggingfaceì— ëŒ€í•´ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. HuggingfaceëŠ” ì»¤ë®¤ë‹ˆí‹° ë° Data Science í”Œë«í¼ìœ¼ë¡œ ëª¨ë¸ê³¼ ë°ì´í„° ë° ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ”ë°ìš”. ëŒ€í‘œì ìœ¼ë¡œ ëª¨ë¸ë“¤ì„ ì°¾ì•„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ê³¼ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì´ì•¼ê¸° í–ˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì˜ ì½”ë“œì— ë§ëŠ” ë°ì´í„°ì„ ì°¾ì•„ ì ìš©í•˜ê±°ë‚˜ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì„ í†µí•´ ì„±ëŠ¥ ê°œì„ ì„ í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
